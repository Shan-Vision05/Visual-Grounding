# Visual-Grounding
This repository implements a PyTorch based visual grounding model that fuses image region features and text features via a multi-step Modular Co-Attention to accurately localize referring expressions.
